from tweepy import OAuthHandler
from tweepy.streaming import StreamListener
import tweepy
import json
import pandas as pd
import csv
import re
from textblob import TextBlob
import string
import preprocessor as p
import os
import time
from datetime import datetime

# Twitter credentials
# Obtained fomy my Twitter developer account
ACCESS_TOKEN = "**"
ACCESS_TOKEN_SECRET = "**"
CONSUMER_KEY = "**"
CONSUMER_SECRET = "**"

#Keys not provided for privacy reasons
auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
api = tweepy.API(auth, wait_on_rate_limit=True)

# Function for Twitter Scraper
def scraptweets(search_words, date_since, date_untill, numTweets, numRuns):
    
    
    # Creating a pandas dataframe to direct to scraped tweets to:
    db_tweets = pd.DataFrame(columns = ['username', 'location', 'following',
                                        'followers', 'totaltweets', 'tweetcreatedts',
                                        'retweetcount', 'text', 'hashtags']
                                )
    program_start = time.time()
    for i in range(0, numRuns):
        # Timer on how long it will take for the Scraper:
        start_run = time.time()
        
        # Cursor object used to collect the tweets
        # .Cursor() gives the ability to set the arguments to specifically query using Tweepy         
        tweets = tweepy.Cursor(api.search, q=search_words, lang="en", since=date_since, until=date_untill, tweet_mode='extended').items(numTweets)
        # Python list where the tweets are listed 
        tweet_list = [tweet for tweet in tweets]
        
        
        # Columns on which the data is scraped 
        noTweets = 0 
        
        for tweet in tweet_list: 
            username = tweet.user.screen_name
            location = tweet.user.location
            following = tweet.user.friends_count
            followers = tweet.user.followers_count
            totaltweets = tweet.user.statuses_count
            tweetcreatedts = tweet.created_at
            retweetcount = tweet.retweet_count
            hashtags = tweet.entities['hashtags']
            
            #For handling Retweets 
            try:
                text = tweet.retweeted_status.full_text
            except AttributeError:  # Not a Retweet
                text = tweet.full_text
                
                
                # Add the 9 variables to the empty list - ith_tweet:
            ith_tweet = [username, location, following, followers, totaltweets,
                       tweetcreatedts, retweetcount, text, hashtags]# Append to dataframe - db_tweets
            db_tweets.loc[len(db_tweets)] = ith_tweet
            
            # Increase counter for the number of tweets which was first set to 0   
            noTweets += 1
        
        # End the run: 
        end_run = time.time()
        #Calculation on the duration
        duration_run = round((end_run-start_run)/60, 2)
        

        print('no. of tweets scraped for run {} is {}'.format(i + 1, noTweets))
        print('time take for {} run to complete is {} mins'.format(i+1, duration_run))
        
        #Sleep time to comply to the Twitter Rate Limits
        time.sleep(920) 
    
    # Obtain timestamp in a readable format
    to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')
    
    # Define working path and filename
    path = os.getcwd()
    filename = path + '/data/' + to_csv_timestamp + '_USelection_tweets.csv'
    
    # Store dataframe in csv with creation date timestamp
    db_tweets.to_csv(filename, index = False)
    
    program_end = time.time()
    print('Scraping has completed!')
    print('Total time taken to scrap is {} minutes.'.format(round(program_end - program_start)/60, 2))
    
    # Initialise variables for the run:
search_words = "#republican OR #conservative OR #trump OR #donaldtrump OR #maga OR #democrat OR #liberal OR #biden OR #joebiden OR #voteblue"
date_since = "2020-11-10"
date_untill = "2020-11-11" 
numTweets = 450
numRuns = 32

# Call the function scraptweets
scraptweets(search_words, date_since, date_untill, numTweets, numRuns)
